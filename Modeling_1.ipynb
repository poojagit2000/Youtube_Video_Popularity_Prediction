{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d683ac02-d991-4e91-b1ab-5aff661c49c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28b3413-d9ff-40b5-91f1-2ea760920432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b6e7c2-0c39-4958-ad22-a970029e9d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>daily_rank</th>\n",
       "      <th>daily_movement</th>\n",
       "      <th>weekly_movement</th>\n",
       "      <th>country</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>description</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>langauge</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption_status</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>description_processed</th>\n",
       "      <th>video_tags_processed</th>\n",
       "      <th>channel_title_processed</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>publish_dayofweek</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Discord Loot Boxes are here.</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>US</td>\n",
       "      <td>1407108038</td>\n",
       "      <td>69908</td>\n",
       "      <td>7789</td>\n",
       "      <td>Why would we ever bring Loot Boxes into a chat...</td>\n",
       "      <td>cc2-4ci4G84</td>\n",
       "      <td>UCZ5XnGb-3t7jCkXdawN2tkA</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-04-01 00:00:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Discord</td>\n",
       "      <td>24.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>discord loot box</td>\n",
       "      <td>would ever bring loot box chat app open discor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discord</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Theft Auto VI Trailer 1</td>\n",
       "      <td>14</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>US</td>\n",
       "      <td>130980218</td>\n",
       "      <td>10301883</td>\n",
       "      <td>802501</td>\n",
       "      <td>Song: Love Is A Long Road\\nArtist: Tom Petty\\n...</td>\n",
       "      <td>QdBZY2fkU-0</td>\n",
       "      <td>UC6VcWc1rAoWdBCM0JxrRQ3A</td>\n",
       "      <td>Rockstar Games, Grand Theft Auto VI, GTAVI, GT...</td>\n",
       "      <td>2023-12-04 00:00:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>20.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>grand theft auto vi trailer</td>\n",
       "      <td>song love long road artist tom petty written t...</td>\n",
       "      <td>rockstar game grand theft auto vi gtavi gta gt...</td>\n",
       "      <td>rockstar game</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Survived 7 Days In An Abandoned City</td>\n",
       "      <td>50</td>\n",
       "      <td>-29</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>99937514</td>\n",
       "      <td>4271480</td>\n",
       "      <td>160164</td>\n",
       "      <td>This was one of the hardest challenges weâve...</td>\n",
       "      <td>tWYsfOSY9vY</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-03-02 00:00:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>24.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>survived day abandoned city</td>\n",
       "      <td>one hardest challenge weve ever done deal good...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mrbeast</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  daily_rank  daily_movement  \\\n",
       "0            Discord Loot Boxes are here.           1              49   \n",
       "1           Grand Theft Auto VI Trailer 1          14              -9   \n",
       "2  I Survived 7 Days In An Abandoned City          50             -29   \n",
       "\n",
       "   weekly_movement country  view_count  like_count  comment_count  \\\n",
       "0               49      US  1407108038       69908           7789   \n",
       "1               36      US   130980218    10301883         802501   \n",
       "2                0      US    99937514     4271480         160164   \n",
       "\n",
       "                                         description     video_id  \\\n",
       "0  Why would we ever bring Loot Boxes into a chat...  cc2-4ci4G84   \n",
       "1  Song: Love Is A Long Road\\nArtist: Tom Petty\\n...  QdBZY2fkU-0   \n",
       "2  This was one of the hardest challenges weâve...  tWYsfOSY9vY   \n",
       "\n",
       "                 channel_id  \\\n",
       "0  UCZ5XnGb-3t7jCkXdawN2tkA   \n",
       "1  UC6VcWc1rAoWdBCM0JxrRQ3A   \n",
       "2  UCX6OQ3DkcsbYNE6H8uQQuVA   \n",
       "\n",
       "                                          video_tags  \\\n",
       "0                                                  -   \n",
       "1  Rockstar Games, Grand Theft Auto VI, GTAVI, GT...   \n",
       "2                                                  -   \n",
       "\n",
       "                publish_date langauge   channel_title  category_id definition  \\\n",
       "0  2024-04-01 00:00:00+00:00       en         Discord         24.0         hd   \n",
       "1  2023-12-04 00:00:00+00:00       en  Rockstar Games         20.0         hd   \n",
       "2  2024-03-02 00:00:00+00:00       en         MrBeast         24.0         hd   \n",
       "\n",
       "   caption_status              title_processed  \\\n",
       "0           False             discord loot box   \n",
       "1            True  grand theft auto vi trailer   \n",
       "2            True  survived day abandoned city   \n",
       "\n",
       "                               description_processed  \\\n",
       "0  would ever bring loot box chat app open discor...   \n",
       "1  song love long road artist tom petty written t...   \n",
       "2  one hardest challenge weve ever done deal good...   \n",
       "\n",
       "                                video_tags_processed channel_title_processed  \\\n",
       "0                                                NaN                 discord   \n",
       "1  rockstar game grand theft auto vi gtavi gta gt...           rockstar game   \n",
       "2                                                NaN                 mrbeast   \n",
       "\n",
       "   publish_year  publish_month  publish_day  publish_dayofweek  \\\n",
       "0          2024              4            1                  0   \n",
       "1          2023             12            4                  0   \n",
       "2          2024              3            2                  5   \n",
       "\n",
       "   duration_seconds  \n",
       "0                18  \n",
       "1                91  \n",
       "2              1044  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = pd.read_csv('cleaned_data.csv')\n",
    "youtube.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8555e954-c179-401c-97c7-56087a5b4148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                         0\n",
       "daily_rank                    0\n",
       "daily_movement                0\n",
       "weekly_movement               0\n",
       "country                       0\n",
       "view_count                    0\n",
       "like_count                    0\n",
       "comment_count                 0\n",
       "description                   0\n",
       "video_id                      0\n",
       "channel_id                    0\n",
       "video_tags                    0\n",
       "publish_date                  0\n",
       "langauge                      0\n",
       "channel_title                 0\n",
       "category_id                   0\n",
       "definition                    0\n",
       "caption_status                0\n",
       "title_processed               7\n",
       "description_processed        62\n",
       "video_tags_processed       1712\n",
       "channel_title_processed      17\n",
       "publish_year                  0\n",
       "publish_month                 0\n",
       "publish_day                   0\n",
       "publish_dayofweek             0\n",
       "duration_seconds              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dca801-f703-48d8-b091-05e0e3fb97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = youtube.replace(np.nan, ' ')\n",
    "youtube.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a933448-a152-4767-912d-41f6dcc821f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10246 entries, 0 to 10245\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   daily_rank               10246 non-null  int64 \n",
      " 1   daily_movement           10246 non-null  int64 \n",
      " 2   weekly_movement          10246 non-null  int64 \n",
      " 3   country                  10246 non-null  object\n",
      " 4   view_count               10246 non-null  int64 \n",
      " 5   like_count               10246 non-null  int64 \n",
      " 6   comment_count            10246 non-null  int64 \n",
      " 7   publish_date             10246 non-null  object\n",
      " 8   langauge                 10246 non-null  object\n",
      " 9   definition               10246 non-null  object\n",
      " 10  caption_status           10246 non-null  bool  \n",
      " 11  title_processed          10246 non-null  object\n",
      " 12  description_processed    10246 non-null  object\n",
      " 13  video_tags_processed     10246 non-null  object\n",
      " 14  channel_title_processed  10246 non-null  object\n",
      " 15  publish_year             10246 non-null  int64 \n",
      " 16  publish_month            10246 non-null  int64 \n",
      " 17  publish_day              10246 non-null  int64 \n",
      " 18  publish_dayofweek        10246 non-null  int64 \n",
      " 19  duration_seconds         10246 non-null  int64 \n",
      "dtypes: bool(1), int64(11), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Assuming `youtube` is your DataFrame\n",
    "youtube = youtube.drop(columns=['title', 'description', 'channel_title', 'video_tags', 'video_id', 'channel_id','category_id'], axis=1)\n",
    "youtube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c59e4e-6478-4b5f-a60b-07a3733998ec",
   "metadata": {},
   "source": [
    "# Use Case 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa4ab3-c937-47ae-88af-f204e026e67a",
   "metadata": {},
   "source": [
    "# Predict Video Popularity with Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98ac192-f29e-40dc-86ae-b0ad5968f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are present.\n",
      "Training Linear Regression...\n",
      "Linear Regression - Mean Squared Error: 0.46089019075834176, R^2 Score: 0.6972873487966924, RMSE: 0.6788889384563146\n",
      "Linear Regression model saved as linear_regression_1.pkl\n",
      "Training Ridge Regression...\n",
      "Ridge Regression - Mean Squared Error: 0.27297721331756214, R^2 Score: 0.8207085817437644, RMSE: 0.5224722129621461\n",
      "Ridge Regression model saved as ridge_regression_1.pkl\n",
      "Training Lasso Regression...\n",
      "Lasso Regression - Mean Squared Error: 1.5238811368763332, R^2 Score: -0.0008850444474250985, RMSE: 1.2344558059632322\n",
      "Lasso Regression model saved as lasso_regression_1.pkl\n",
      "Training K Nearest Neighbors...\n",
      "K Nearest Neighbors - Mean Squared Error: 0.5242938267196654, R^2 Score: 0.655643844285994, RMSE: 0.7240813674716851\n",
      "K Nearest Neighbors model saved as k_nearest_neighbors_1.pkl\n",
      "Training Support Vector Machine...\n",
      "Support Vector Machine - Mean Squared Error: 0.23285886048160317, R^2 Score: 0.8470583136156898, RMSE: 0.48255451555404927\n",
      "Support Vector Machine model saved as support_vector_machine_1.pkl\n",
      "Training Decision Tree...\n",
      "Decision Tree - Mean Squared Error: 0.5331912840761397, R^2 Score: 0.6497999947978653, RMSE: 0.73019948238556\n",
      "Decision Tree model saved as decision_tree_1.pkl\n",
      "Training XGBoost...\n",
      "XGBoost - Mean Squared Error: 0.2533024823276303, R^2 Score: 0.8336309439443453, RMSE: 0.5032916473851223\n",
      "XGBoost model saved as xgboost_1.pkl\n",
      "All models trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Define numerical, categorical, and text features\n",
    "numerical_features = ['duration_seconds','daily_rank','daily_movement','weekly_movement','like_count','comment_count']\n",
    "categorical_features = ['country', 'langauge', 'definition', 'caption_status', 'publish_year', 'publish_month', 'publish_day', 'publish_dayofweek']\n",
    "text_features = ['title_processed', 'description_processed', 'video_tags_processed', 'channel_title_processed']\n",
    "\n",
    "# Check for missing columns\n",
    "missing_columns = set(numerical_features + categorical_features + text_features) - set(youtube.columns)\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns in the DataFrame: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All required columns are present.\")\n",
    "\n",
    "# Apply log transformation to like_count and comment_count\n",
    "youtube['like_count'] = np.log1p(youtube['like_count'])\n",
    "youtube['comment_count'] = np.log1p(youtube['comment_count'])\n",
    "\n",
    "# Define preprocessing steps\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "text_transformers = [(text_feature, Pipeline(steps=[('tfidf', TfidfVectorizer(max_features=15000))]), text_feature) for text_feature in text_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ] + text_transformers)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'K Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = youtube.drop(columns=['view_count'])  # Features\n",
    "y = np.log1p(youtube['view_count'])  # Log-transformed target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train, evaluate, and pickle each model\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    # Create a pipeline with the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    print(f\"{name} - Mean Squared Error: {mse}, R^2 Score: {r2}, RMSE: {rmse}\")\n",
    "    \n",
    "    # Pickle the model\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_1.pkl\"\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(pipeline, file)\n",
    "        print(f\"{name} model saved as {model_filename}\")\n",
    "\n",
    "print(\"All models trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955e5c4-43bf-4ce5-bac4-96c24bdbcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length features\n",
    "for feature in text_features:\n",
    "    youtube[feature + '_length'] = youtube[feature].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Add the text length features to the list of numerical features\n",
    "numerical_features += [feature + '_length' for feature in text_features]\n",
    "\n",
    "# Log transform the target variable\n",
    "youtube['log_view_count'] = np.log1p(youtube['view_count'])\n",
    "\n",
    "\n",
    "print(\"Columns after adding length features:\", youtube.columns)\n",
    "\n",
    "# Check if all necessary columns are in the DataFrame\n",
    "missing_columns = set(numerical_features + categorical_features + text_features) - set(youtube.columns)\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns in the DataFrame: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All required columns are present.\")\n",
    "\n",
    "# Define preprocessing steps for different types of features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a separate pipeline for each text feature\n",
    "text_transformers = [(text_feature, Pipeline(steps=[('tfidf', TfidfVectorizer(max_features=5000))]), text_feature) for text_feature in text_features]\n",
    "\n",
    "# Combine preprocessing steps for all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ] + text_transformers)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Combine preprocessing and modeling into a single pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = youtube.drop(columns=['view_count', 'log_view_count'])  # Features\n",
    "y = youtube['log_view_count']  # Log-transformed target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting the pipeline...\")\n",
    "try:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"Pipeline fitted successfully.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error during pipeline fitting: {e}\")\n",
    "\n",
    "# Evaluate the model\n",
    "try:\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    #mse = mean_squared_error(np.expm1(y_test), np.expm1(y_pred))  # Reverse log transformation for MSE calculation\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    #r2 = r2_score(np.expm1(y_test), np.expm1(y_pred))  # Reverse log transformation for R² calculation\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R^2 Score:\", r2)\n",
    "    print(\"Root Mean Squared Error:\",rmse)\n",
    "except ValueError as e:\n",
    "    print(f\"Error during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adad179-71be-4f20-bb4a-800e9189c0d5",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
